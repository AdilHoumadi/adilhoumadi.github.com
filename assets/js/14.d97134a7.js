(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{409:function(t,e,s){"use strict";s.r(e);var a=s(10),n=Object(a.a)({},(function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"requirements"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#requirements"}},[t._v("#")]),t._v(" Requirements")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://docs.docker.com/get-docker/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Docker"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[s("a",{attrs:{href:"https://docs.docker.com/compose/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Docker-compose"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[s("a",{attrs:{href:"https://adoptopenjdk.net/installation.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("OpenJDK"),s("OutboundLink")],1),t._v(".")]),t._v(" "),s("li",[s("a",{attrs:{href:"https://stedolan.github.io/jq/",target:"_blank",rel:"noopener noreferrer"}},[t._v("jq"),s("OutboundLink")],1),t._v(".")])]),t._v(" "),s("h2",{attrs:{id:"introduction"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[t._v("#")]),t._v(" Introduction")]),t._v(" "),s("p",[t._v("In this series of articles we will see the different methods that we can use in order to produce data to a topic, and the way to consume it. We will start by setting up a local environment using docker and docker-compose. Once the kafka ecosystem is ready we will create a topic, than produce some data and consume it via CLI.")]),t._v(" "),s("h2",{attrs:{id:"local-environment"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#local-environment"}},[t._v("#")]),t._v(" Local environment")]),t._v(" "),s("p",[t._v("Using the following "),s("code",[t._v("docker-compose")]),t._v(" we will be able to start a local environment that contain: a "),s("code",[t._v("broker")]),t._v(" and "),s("code",[t._v("zookeeper")]),t._v(".")]),t._v(" "),s("p",[t._v("docker-compose.yml")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("---")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("version")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2'")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("services")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("zookeeper")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("image")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" confluentinc/cp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("zookeeper"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("6.0.0\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("hostname")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" zookeeper\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("container_name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" zookeeper\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("ports")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2181:2181"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("environment")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("ZOOKEEPER_CLIENT_PORT")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2181")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("ZOOKEEPER_TICK_TIME")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),t._v("\n\n\n  "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("broker")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("image")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" confluentinc/cp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("kafka"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("6.0.0\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("hostname")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" broker\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("container_name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" broker\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("depends_on")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" zookeeper\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("ports")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"9092:9092"')]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"9101:9101"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("environment")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("KAFKA_BROKER_ID")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("KAFKA_ZOOKEEPER_CONNECT")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'zookeeper:2181'")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("KAFKA_LISTENER_SECURITY_PROTOCOL_MAP")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" PLAINTEXT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("PLAINTEXT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("PLAINTEXT_HOST"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("PLAINTEXT\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("KAFKA_ADVERTISED_LISTENERS")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" PLAINTEXT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//broker"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("29092")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("PLAINTEXT_HOST"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//localhost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9092")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n")])])]),s("p",[t._v("Start the local environment by executing this command:")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("$ docker-compose up -d\n")])])]),s("p",[t._v("Check if the environment is ready:")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("$ docker-compose "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("ps")]),t._v("\n\n  Name               Command            State                       Ports\n----------------------------------------------------------------------------------------------\nbroker      /etc/confluent/docker/run   Up      "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v(".0.0:9092-"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9092")]),t._v("/tcp, "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v(".0.0:9101-"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9101")]),t._v("/tcp\nzookeeper   /etc/confluent/docker/run   Up      "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v(".0.0:2181-"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2181")]),t._v("/tcp, "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2888")]),t._v("/tcp, "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3888")]),t._v("/tcp\n")])])]),s("h2",{attrs:{id:"setup-kafka-cli"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#setup-kafka-cli"}},[t._v("#")]),t._v(" Setup kafka CLI")]),t._v(" "),s("p",[t._v("In order to interact with the kafka broker, Apache Kafka provides a client CLI:")]),t._v(" "),s("div",{staticClass:"language-sh extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sh"}},[s("code",[t._v("$ "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -L https://archive.apache.org/dist/kafka/2.6.0/kafka_2.13-2.6.0.tgz "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" kafka_2.13-2.6.0.tgz\n$ "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tar")]),t._v(" -xvf kafka_2.13-2.6.0.tgz\n$ "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" kafka_2.13-2.6.0\n$ "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("PATH")])]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("$PWD")]),t._v("/bin:"),s("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("$PATH")]),t._v("\n$ "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("ls")]),t._v(" -a kafka-console*                   \n\nkafka-console-consumer.sh  kafka-console-producer.sh\n")])])]),s("blockquote",[s("p",[t._v("Add this export to your shell profile, it will allow to execute the bin from any location in the system.")])]),t._v(" "),s("h2",{attrs:{id:"create-the-topic"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#create-the-topic"}},[t._v("#")]),t._v(" Create the topic")]),t._v(" "),s("p",[t._v("In order to create the topic, we will need to use "),s("code",[t._v("kafka-topics.sh")]),t._v(" command and set the required parameters:")]),t._v(" "),s("div",{staticClass:"language-sh extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sh"}},[s("code",[t._v("$ kafka-topics.sh "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --bootstrap-server localhost:9092 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --create "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --topic newTopic "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --partitions "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --replication-factor "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\nCreated topic newTopic.\n")])])]),s("ul",[s("li",[s("code",[t._v("localhost:9092")]),t._v(" - the broker address")]),t._v(" "),s("li",[s("code",[t._v("newTopic")]),t._v(" - the topic name")]),t._v(" "),s("li",[s("code",[t._v("3")]),t._v(" -  The number of partitions for topic")]),t._v(" "),s("li",[s("code",[t._v("1")]),t._v(" -  The number of replication for the topic, in our environment we have only on broker.S")])]),t._v(" "),s("p",[t._v("To check the creation of the topic we will use the previous command with "),s("code",[t._v("--list")]),t._v(" option.")]),t._v(" "),s("div",{staticClass:"language-sh extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sh"}},[s("code",[t._v("$ kafka-topics.sh --bootstrap-server localhost:9092 --list\n\nnewTopic\n")])])]),s("p",[t._v("To Have more details about the topic that has been creation, there is an option that we can set to "),s("code",[t._v("kafka-topics.sh")]),t._v(" which is called "),s("code",[t._v("--describe")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-sh extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sh"}},[s("code",[t._v("$ kafka-topics.sh --bootstrap-server localhost:9092 --describe\n\nTopic: newTopic PartitionCount: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("       ReplicationFactor: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("    Configs:\n        Topic: newTopic Partition: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("    Leader: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       Replicas: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("     Isr: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n        Topic: newTopic Partition: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("    Leader: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       Replicas: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("     Isr: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n        Topic: newTopic Partition: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("    Leader: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       Replicas: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("     Isr: "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),s("p",[t._v("The output of the command give us the number of partitions and the replicas.\nIn our case we are using only on instance for the broker which is obviously refer to the number of replicas.")]),t._v(" "),s("blockquote",[s("p",[t._v("In a future article we can discuss a setup that contain a cluster with multiple brokers.")])]),t._v(" "),s("h2",{attrs:{id:"produce-the-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#produce-the-data"}},[t._v("#")]),t._v(" Produce the data")]),t._v(" "),s("p",[t._v("Now that we have our topic created in the broker and we could describe its configuration, we can start producing messages.")]),t._v(" "),s("p",[t._v("In order to send messages to our topic we will use "),s("code",[t._v("kafka-console-producer.sh")]),t._v(".\nAn interactive prompt will be shown and we can start writing our messages.")]),t._v(" "),s("p",[t._v("To confirm the sending of the message we need to hit "),s("code",[t._v("ENTER")]),t._v(" and continue.")]),t._v(" "),s("p",[t._v("Once we finish our sending we can quit the process using "),s("code",[t._v("CTRL+C")])]),t._v(" "),s("div",{staticClass:"language-sh extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sh"}},[s("code",[t._v("$ kafka-console-producer.sh --bootstrap-server localhost:9092 --topic newTopic\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("Hello world\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("Bonjour monde\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("Hola mundo\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("^C\n")])])]),s("blockquote",[s("p",[s("code",[t._v("DETAIL")]),t._v(": We can start producing the data without creation of the topic. A question that we can ask ourself is the following: Why we took the time to create the topic before sending the messages? Usually in production environment the "),s("code",[t._v("auto-creation")]),t._v(" for topics is disabled by default, Organizations prefer to have control and approve the creation of topics, if we want to have this behavior in our setup we can set this environment variable in our docker-compose.yml")])]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("KAFKA_AUTO_CREATE_TOPICS_ENABLE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"false"')]),t._v("\n")])])]),s("p",[t._v("To make the production of the data more interesting we can use Meetup Streaming API.\nThe following endpoint will stream open events from Meetup-API:")]),t._v(" "),s("div",{staticClass:"language-yaml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-yaml"}},[s("code",[t._v("https"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//stream.meetup.com/2/open_events\n")])])]),s("p",[t._v("We need to execute this command to have a continuous flow from Meetup-API")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("curl")]),t._v(" -s https://stream.meetup.com/2/open_events "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" jq -c --unbuffered "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'{id: .id, event_url: .event_url, name: .name}'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" kafka-console-producer.sh --bootstrap-server localhost:9092 --topic newTopic\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("We execute a "),s("code",[t._v("GET")]),t._v(" Request via "),s("code",[t._v("curl")]),t._v(" on Meetup-API and we pipe the result to "),s("code",[t._v("jq")]),t._v(" to map the output and get the following fields:")]),t._v(" "),s("ul",[s("li",[t._v("id")]),t._v(" "),s("li",[t._v("event_url")]),t._v(" "),s("li",[t._v("name")])]),t._v(" "),s("p",[t._v("For each message produced to the topic a "),s("code",[t._v(">")]),t._v(" will be printed to the terminal. We keep running this command in a tab to feed our topic. We will end up having json objects in our topic that look like the following structure:")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hfhhvqyccgbnb"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"event_url"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://www.meetup.com/Hamburg-Soccer-Meetup/events/hfhhvqyccgbnb/"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Outdoor Football 8v8"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("h2",{attrs:{id:"consume-the-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#consume-the-data"}},[t._v("#")]),t._v(" Consume the data")]),t._v(" "),s("p",[t._v("In the section we will spawn a new terminal to consume the data that has been produced previously.\nTo do so, we will need "),s("code",[t._v("kafka-console-consumer.sh")]),t._v(" binary and set the required parameters to start the consumption.")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic newTopic --from-beginning\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"277066021"')]),t._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"event_url"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://www.meetup.com/Detroit-Young-Professional-Happy-Hour/events/277066021/"')]),t._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Make New Friends - Singles Mixer (36-47)"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"277066034"')]),t._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"event_url"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://www.meetup.com/Fun-Chefs/events/277066034/"')]),t._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"New Friends - Single Professionals Mixer (36-47 group)"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),t._v(".\nProcessed a total of "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("103")]),t._v(" messages\n")])])]),s("ul",[s("li",[s("code",[t._v("--from-beginning")]),t._v(": it allows to start consuming the data from the first offset.")])]),t._v(" "),s("p",[t._v("We can play with this command and consume from a specific offset for a specific partition with a fixed number of messages before exiting.")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("$ kafka-console-consumer.sh "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --bootstrap-server localhost:9092 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --topic newTopic "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --offset "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --partition "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --max-messages "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fblqfsyccgbnb"')]),t._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"event_url"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://www.meetup.com/Yoga-Ayurveda-Vedic-Sciences/events/fblqfsyccgbnb/"')]),t._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Yoga in The Park"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nProcessed a total of "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" messages\n")])])]),s("ul",[s("li",[s("code",[t._v("--offset")]),t._v(": rewind the process to the specified offset.")]),t._v(" "),s("li",[s("code",[t._v("--partition")]),t._v(": consume from this specific partition.")]),t._v(" "),s("li",[s("code",[t._v("--max-messages")]),t._v(": total messages to consume before exiting the process.")])]),t._v(" "),s("blockquote",[s("p",[s("code",[t._v("--offset")]),t._v(" accepts an integer and "),s("code",[t._v("earliest")]),t._v(" to start from the beginning or "),s("code",[t._v("latest")]),t._v(" which the default value that mean consume from end.")])]),t._v(" "),s("p",[t._v("To get the status of each partition we can execute this command:")]),t._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[t._v("$ kafka-run-class.sh kafka.tools.GetOffsetShell "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --broker-list localhost:9092 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --topic newTopic\n\nnewTopic:0:34\nnewTopic:1:41\nnewTopic:2:36\n")])])]),s("p",[t._v("We see clearly that our topic has 3 partitions: 0, 1 and 2 and for each partition we have the last offset that has been reached.")]),t._v(" "),s("ul",[s("li",[t._v("partition 0 offset 34")]),t._v(" "),s("li",[t._v("partition 1 offset 41")]),t._v(" "),s("li",[t._v("partition 2 offset 36")])]),t._v(" "),s("h2",{attrs:{id:"conclusion"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[t._v("#")]),t._v(" Conclusion")]),t._v(" "),s("p",[t._v("As you have seen put in place a Kafka local environment is accessible to every developer that is interested to get in Streaming world. In a few minutes, we manage to setup the cluster and start producing and consuming the data.")]),t._v(" "),s("p",[t._v("For testing purpose working with the CLI is fine and allows to prototype quickly.\nBut for production application the Favorite way of producing/consuming the data is via a programming language of or using kafka connector. In the next article we will discuss how we can implement it via the Java SDK.")]),t._v(" "),s("p",[t._v("Stay tuned ✌!")])])}),[],!1,null,null,null);e.default=n.exports}}]);